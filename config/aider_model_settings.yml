# Aider advanced model settings file
# Format: list of dicts. Each entry targets a "name:" model.
# You can also define global extra params via the special model name: aider/extra_params

- name: aider/extra_params
  extra_params:
    # Common defaults sent to litellm.completion() when supported by provider/model
    max_tokens: 4096

# --- Local (Ollama) models ---
- name: ollama/qwen2.5-coder:7b
  edit_format: diff
  use_repo_map: true
  use_system_prompt: true
  streaming: true
  use_temperature: true
  extra_params:
    temperature: 0.4
    max_tokens: 4096

- name: ollama/qwen2.5-coder:32b
  edit_format: diff
  use_repo_map: true
  use_system_prompt: true
  streaming: true
  use_temperature: true
  extra_params:
    temperature: 0.4
    max_tokens: 4096

# --- Local (Ollama) fast model for planning / lightweight edits ---
- name: ollama/llama3.1
  edit_format: diff
  use_repo_map: true
  use_system_prompt: true
  streaming: true
  use_temperature: true
  extra_params:
    temperature: 0.6
    max_tokens: 2048

# --- OpenAI (API) general strong ---
- name: openai/gpt-4o
  edit_format: diff
  use_repo_map: true
  use_system_prompt: true
  streaming: true
  use_temperature: true
  extra_params:
    temperature: 0.4
    max_tokens: 4096

# --- OpenAI (API) fast/cheap ---
- name: openai/gpt-4o-mini
  edit_format: diff
  use_repo_map: true
  use_system_prompt: true
  streaming: true
  use_temperature: true
  extra_params:
    temperature: 0.5
    max_tokens: 2048

# --- Anthropic (API) strong ---
- name: anthropic/claude-3-7-sonnet
  edit_format: diff
  use_repo_map: true
  use_system_prompt: true
  streaming: true
  use_temperature: true
  extra_params:
    temperature: 0.4
    max_tokens: 4096

# --- DeepSeek (API) option ---
- name: deepseek/deepseek-chat
  edit_format: diff
  use_repo_map: true
  use_system_prompt: true
  streaming: true
  use_temperature: true
  extra_params:
    temperature: 0.4
    max_tokens: 4096
