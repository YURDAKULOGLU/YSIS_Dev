ðŸ“š Core Concepts - Ragas







![](https://static.scarf.sh/a.png?x-pxid=f4040c26-97ff-4975-bcbb-8db47063d472)
















[Skip to content](#core-concepts)

**Ragas Office Hours** - If you need help setting up Evals for your AI application, sign up for our
Office Hours [here](https://cal.com/team/vibrantlabs/office-hours).

# ðŸ“š Core Concepts

* [**Experimentation**](experimentation/)

  ---

  Learn how to systematically evaluate your AI applications using experiments.

  Track changes, measure improvements, and compare results across different versions of your application.
* [**Datasets**](datasets/)

  ---

  Understand how to create, manage, and use evaluation datasets.

  Learn about dataset structure, storage backends, and best practices for maintaining your test data.
* : [**Ragas Metrics**](metrics/)

  ---

  Use our library of [available metrics](metrics/available_metrics/) or create [custom metrics](metrics/overview/) tailored to your use case.

  Metrics for evaluating [RAG](metrics/available_metrics/#retrieval-augmented-generation), [Agentic workflows](metrics/available_metrics/#agents-or-tool-use-cases) and [more..](metrics/available_metrics/#list-of-available-metrics).
* [**Test Data Generation**](test_data_generation/)

  ---

  Generate high-quality datasets for comprehensive testing.

  Algorithms for synthesizing data to test [RAG](test_data_generation/rag/), [Agentic workflows](test_data_generation/agents/)

November 28, 2025




November 28, 2025




GitHub

Back to top