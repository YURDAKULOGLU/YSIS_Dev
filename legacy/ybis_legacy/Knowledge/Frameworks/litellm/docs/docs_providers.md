Providers | liteLLM






[Skip to main content](#__docusaurus_skipToContent_fallback)

[## ğŸ“„ï¸ Integrate as a Model Provider

Quick Start for OpenAI-Compatible Providers](/docs/provider_registration/)

[## ğŸ“„ï¸ Add OpenAI-Compatible Provider (JSON)

For simple OpenAI-compatible providers (like Hyperbolic, Nscale, etc.), you can add support by editing a single JSON file.](/docs/contributing/adding_openai_compatible_providers)

[## ğŸ“„ï¸ Add Model Pricing & Context Window

To add pricing or context window information for a model, simply make a PR to this file:](/docs/provider_registration/add_model_pricing)

[## ğŸ—ƒï¸ OpenAI

4 items](/docs/providers/openai)

[## ğŸ“„ï¸ OpenAI (Text Completion)

LiteLLM supports OpenAI text completion models](/docs/providers/text_completion_openai)

[## ğŸ“„ï¸ OpenAI-Compatible Endpoints

Selecting openai as the provider routes your request to an OpenAI-compatible endpoint using the upstream](/docs/providers/openai_compatible)

[## ğŸ—ƒï¸ Azure OpenAI

5 items](/docs/providers/azure/)

[## ğŸ—ƒï¸ Azure AI

8 items](/docs/providers/azure_ai)

[## ğŸ—ƒï¸ Vertex AI

10 items](/docs/providers/vertex)

[## ğŸ—ƒï¸ Google AI Studio

5 items](/docs/providers/gemini)

[## ğŸ“„ï¸ Anthropic

LiteLLM supports all anthropic models.](/docs/providers/anthropic)

[## ğŸ“„ï¸ AWS Sagemaker

LiteLLM supports All Sagemaker Huggingface Jumpstart Models](/docs/providers/aws_sagemaker)

[## ğŸ—ƒï¸ Bedrock

11 items](/docs/providers/bedrock)

[## ğŸ“„ï¸ LiteLLM Proxy (LLM Gateway)

| Property | Details |](/docs/providers/litellm_proxy)

[## ğŸ“„ï¸ AI21

LiteLLM supports the following AI21 models:](/docs/providers/ai21)

[## ğŸ“„ï¸ AI/ML API

https://aimlapi.com/](/docs/providers/aiml)

[## ğŸ“„ï¸ Aleph Alpha

LiteLLM supports all models from Aleph Alpha.](/docs/providers/aleph_alpha)

[## ğŸ“„ï¸ Amazon Nova

| Property | Details |](/docs/providers/amazon_nova)

[## ğŸ“„ï¸ Anyscale

https://app.endpoints.anyscale.com/](/docs/providers/anyscale)

[## ğŸ“„ï¸ Apertis AI (Stima API)

Overview](/docs/providers/apertis)

[## ğŸ“„ï¸ Baseten

LiteLLM supports both Baseten Model APIs and dedicated deployments with automatic routing.](/docs/providers/baseten)

[## ğŸ“„ï¸ Bytez

LiteLLM supports all chat models on Bytez!](/docs/providers/bytez)

[## ğŸ“„ï¸ Cerebras

https://inference-docs.cerebras.ai/api-reference/chat-completions](/docs/providers/cerebras)

[## ğŸ“„ï¸ Chutes

Overview](/docs/providers/chutes)

[## ğŸ“„ï¸ Clarifai

Anthropic, OpenAI, Qwen, xAI, Gemini and most of Open soured LLMs are Supported on Clarifai.](/docs/providers/clarifai)

[## ğŸ“„ï¸ Cloudflare Workers AI

https://developers.cloudflare.com/workers-ai/models/text-generation/](/docs/providers/cloudflare_workers)

[## ğŸ“„ï¸ Codestral API [Mistral AI]

Codestral is available in select code-completion plugins but can also be queried directly. See the documentation for more details.](/docs/providers/codestral)

[## ğŸ“„ï¸ Cohere

API KEYS](/docs/providers/cohere)

[## ğŸ“„ï¸ CometAPI

LiteLLM supports all AI models from CometAPI. CometAPI provides access to 500+ AI models through a unified API interface, including cutting-edge models like GPT-5, Claude Opus 4.1, and various other state-of-the-art language models.](/docs/providers/cometapi)

[## ğŸ“„ï¸ CompactifAI

https://docs.compactif.ai/](/docs/providers/compactifai)

[## ğŸ“„ï¸ Custom API Server (Custom Format)

Call your custom torch-serve / internal LLM APIs via LiteLLM](/docs/providers/custom_llm_server)

[## ğŸ“„ï¸ Dashscope (Qwen API)

https://dashscope.console.aliyun.com/](/docs/providers/dashscope)

[## ğŸ“„ï¸ Databricks

LiteLLM supports all models on Databricks](/docs/providers/databricks)

[## ğŸ“„ï¸ DataRobot

LiteLLM supports all models from DataRobot. Select datarobot as the provider to route your request through the datarobot OpenAI-compatible endpoint using the upstream official OpenAI Python API library.](/docs/providers/datarobot)

[## ğŸ“„ï¸ Deepgram

LiteLLM supports Deepgram's /listen endpoint.](/docs/providers/deepgram)

[## ğŸ“„ï¸ DeepInfra

https://deepinfra.com/](/docs/providers/deepinfra)

[## ğŸ“„ï¸ Deepseek

https://deepseek.com/](/docs/providers/deepseek)

[## ğŸ“„ï¸ Docker Model Runner

Overview](/docs/providers/docker_model_runner)

[## ğŸ“„ï¸ ElevenLabs

ElevenLabs provides high-quality AI voice technology, including speech-to-text capabilities through their transcription API.](/docs/providers/elevenlabs)

[## ğŸ“„ï¸ Fal AI

Fal AI provides fast, scalable access to state-of-the-art image generation models including FLUX, Stable Diffusion, Imagen, and more.](/docs/providers/fal_ai)

[## ğŸ“„ï¸ Featherless AI

https://featherless.ai/](/docs/providers/featherless_ai)

[## ğŸ“„ï¸ Fireworks AI

We support ALL Fireworks AI models, just set fireworks\_ai/ as a prefix when sending completion requests](/docs/providers/fireworks_ai)

[## ğŸ“„ï¸ FriendliAI

We support ALL FriendliAI models, just set friendliai/ as a prefix when sending completion requests](/docs/providers/friendliai)

[## ğŸ“„ï¸ Galadriel

https://docs.galadriel.com/api-reference/chat-completion-API](/docs/providers/galadriel)

[## ğŸ“„ï¸ Github

https://github.com/marketplace/models](/docs/providers/github)

[## ğŸ“„ï¸ GitHub Copilot

https://docs.github.com/en/copilot](/docs/providers/github_copilot)

[## ğŸ“„ï¸ GradientAI

https://digitalocean.com/products/gradientai](/docs/providers/gradient_ai)

[## ğŸ“„ï¸ Groq

https://groq.com/](/docs/providers/groq)

[## ğŸ“„ï¸ Helicone

Overview](/docs/providers/helicone)

[## ğŸ“„ï¸ Heroku

Provision a Model](/docs/providers/heroku)

[## ğŸ—ƒï¸ HuggingFace

2 items](/docs/providers/huggingface)

[## ğŸ“„ï¸ Hyperbolic

Overview](/docs/providers/hyperbolic)

[## ğŸ“„ï¸ Infinity

| Property | Details |](/docs/providers/infinity)

[## ğŸ“„ï¸ Jina AI

https://jina.ai/embeddings/](/docs/providers/jina_ai)

[## ğŸ“„ï¸ Lambda AI

Overview](/docs/providers/lambda_ai)

[## ğŸ“„ï¸ LangGraph

Call LangGraph agents through LiteLLM using the OpenAI chat completions format.](/docs/providers/langgraph)

[## ğŸ“„ï¸ Lemonade

Lemonade Server is an OpenAI-compatible local language model inference provider optimized for AMD GPUs and NPUs. The lemonade litellm provider supports standard chat completions with full OpenAI API compatibility.](/docs/providers/lemonade)

[## ğŸ“„ï¸ Llamafile

LiteLLM supports all models on Llamafile.](/docs/providers/llamafile)

[## ğŸ“„ï¸ LM Studio

https://lmstudio.ai/docs/basics/server](/docs/providers/lm_studio)

[## ğŸ“„ï¸ Meta Llama

| Property | Details |](/docs/providers/meta_llama)

[## ğŸ“„ï¸ Milvus - Vector Store

Use Milvus as a vector store for RAG.](/docs/providers/milvus_vector_stores)

[## ğŸ“„ï¸ Mistral AI API

https://docs.mistral.ai/api/](/docs/providers/mistral)

[## ğŸ“„ï¸ MiniMax

Overview](/docs/providers/minimax)

[## ğŸ“„ï¸ Moonshot AI

Overview](/docs/providers/moonshot)

[## ğŸ“„ï¸ Morph

LiteLLM supports all models on Morph](/docs/providers/morph)

[## ğŸ“„ï¸ Nebius AI Studio

https://docs.nebius.com/studio/inference/quickstart](/docs/providers/nebius)

[## ğŸ“„ï¸ NLP Cloud

LiteLLM supports all LLMs on NLP Cloud.](/docs/providers/nlp_cloud)

[## ğŸ“„ï¸ NanoGPT

Overview](/docs/providers/nano-gpt)

[## ğŸ“„ï¸ Novita AI

| Property | Details |](/docs/providers/novita)

[## ğŸ“„ï¸ Nscale (EU Sovereign)

https://docs.nscale.com/docs/inference/chat](/docs/providers/nscale)

[## ğŸ—ƒï¸ Nvidia NIM

2 items](/docs/providers/nvidia_nim)

[## ğŸ“„ï¸ Oracle Cloud Infrastructure (OCI)

LiteLLM supports the following models for OCI on-demand GenAI API.](/docs/providers/oci)

[## ğŸ“„ï¸ Ollama

LiteLLM supports all models from Ollama](/docs/providers/ollama)

[## ğŸ“„ï¸ OpenRouter

LiteLLM supports all the text / chat / vision models from OpenRouter](/docs/providers/openrouter)

[## ğŸ“„ï¸ ğŸ†• OVHCloud AI Endpoints

Leading French Cloud provider in Europe with data sovereignty and privacy.](/docs/providers/ovhcloud)

[## ğŸ“„ï¸ Perplexity AI (pplx-api)

https://www.perplexity.ai](/docs/providers/perplexity)

[## ğŸ“„ï¸ Petals

Petals//github.com/bigscience-workshop/petals](/docs/providers/petals)

[## ğŸ“„ï¸ Poe

Overview](/docs/providers/poe)

[## ğŸ“„ï¸ PublicAI

Overview](/docs/providers/publicai)

[## ğŸ“„ï¸ Predibase

LiteLLM supports all models on Predibase](/docs/providers/predibase)

[## ğŸ“„ï¸ Pydantic AI Agents

Call Pydantic AI Agents via LiteLLM's A2A Gateway.](/docs/providers/pydantic_ai_agent)

[## ğŸ“„ï¸ RAGFlow

Litellm supports Ragflow's chat completions APIs](/docs/providers/ragflow)

[## ğŸ“„ï¸ Recraft

https://www.recraft.ai/](/docs/providers/recraft)

[## ğŸ“„ï¸ Replicate

LiteLLM supports all models on Replicate](/docs/providers/replicate)

[## ğŸ—ƒï¸ RunwayML

2 items](/docs/providers/runwayml/images)

[## ğŸ“„ï¸ SambaNova

https://cloud.sambanova.ai/](/docs/providers/sambanova)

[## ğŸ“„ï¸ SAP Generative AI Hub

LiteLLM supports SAP Generative AI Hub's Orchestration Service.](/docs/providers/sap)

[## ğŸ“„ï¸ Stability AI

https://stability.ai/](/docs/providers/stability)

[## ğŸ“„ï¸ Synthetic

Overview](/docs/providers/synthetic)

[## ğŸ“„ï¸ Snowflake

| Property | Details |](/docs/providers/snowflake)

[## ğŸ“„ï¸ Together AI

LiteLLM supports all models on Together AI.](/docs/providers/togetherai)

[## ğŸ“„ï¸ Topaz

| Property | Details |](/docs/providers/topaz)

[## ğŸ“„ï¸ Triton Inference Server

LiteLLM supports Embedding Models on Triton Inference Servers](/docs/providers/triton-inference-server)

[## ğŸ“„ï¸ v0

Overview](/docs/providers/v0)

[## ğŸ“„ï¸ Vercel AI Gateway

Overview](/docs/providers/vercel_ai_gateway)

[## ğŸ—ƒï¸ vLLM

2 items](/docs/providers/vllm)

[## ğŸ“„ï¸ Volcano Engine (Volcengine)

https://www.volcengine.com/docs/82379/1263482](/docs/providers/volcano)

[## ğŸ“„ï¸ Voyage AI

https://docs.voyageai.com/embeddings/](/docs/providers/voyage)

[## ğŸ“„ï¸ Weights & Biases Inference

https://weave-docs.wandb.ai/quickstart-inference](/docs/providers/wandb_inference)

[## ğŸ—ƒï¸ WatsonX

2 items](/docs/providers/watsonx/)

[## ğŸ“„ï¸ xAI

https://docs.x.ai/docs](/docs/providers/xai)

[## ğŸ“„ï¸ Xiaomi MiMo

https://platform.xiaomimimo.com/#/docs](/docs/providers/xiaomi_mimo)

[## ğŸ“„ï¸ Xinference [Xorbits Inference]

https://inference.readthedocs.io/en/latest/index.html](/docs/providers/xinference)

[## ğŸ“„ï¸ Z.AI (Zhipu AI)

https://z.ai/](/docs/providers/zai)