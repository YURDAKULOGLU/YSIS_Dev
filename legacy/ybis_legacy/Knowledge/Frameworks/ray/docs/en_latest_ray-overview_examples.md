Examples — Ray 2.53.0


[Skip to main content](#main-content)

Back to top





`Ctrl`+`K`

Try Ray with $100 credit — [Start now](https://console.anyscale.com/register/ha?render_flow=ray&utm_source=ray_docs&utm_medium=docs&utm_campaign=banner)×

[Try Managed Ray](https://console.anyscale.com/register/ha?render_flow=ray&utm_source=ray_docs&utm_medium=docs&utm_campaign=navbar)

# Examples[#](#examples "Link to this heading")

* [Multi-modal AI pipeline](e2e-multimodal-ai-workloads/README.html)
  + [Development](e2e-multimodal-ai-workloads/README.html#development)
  + [Production](e2e-multimodal-ai-workloads/README.html#production)
  + [No infrastructure headaches](e2e-multimodal-ai-workloads/README.html#no-infrastructure-headaches)
* [LLM training and inference](entity-recognition-with-llms/README.html)
  + [Set up](entity-recognition-with-llms/README.html#set-up)
  + [Data ingestion](entity-recognition-with-llms/README.html#data-ingestion)
  + [Distributed fine-tuning](entity-recognition-with-llms/README.html#distributed-fine-tuning)
  + [Batch inference](entity-recognition-with-llms/README.html#batch-inference)
  + [Online serving](entity-recognition-with-llms/README.html#online-serving)
  + [Production](entity-recognition-with-llms/README.html#production)
* [Audio batch inference](e2e-audio/README.html)
  + [Prerequisites](e2e-audio/README.html#prerequisites)
  + [Setup](e2e-audio/README.html#setup)
  + [Streaming data ingestion](e2e-audio/README.html#streaming-data-ingestion)
  + [Audio preprocessing](e2e-audio/README.html#audio-preprocessing)
  + [GPU inference with Whisper](e2e-audio/README.html#gpu-inference-with-whisper)
  + [LLM-based quality filter](e2e-audio/README.html#llm-based-quality-filter)
  + [Persist the curated subset](e2e-audio/README.html#persist-the-curated-subset)
* [Distributed XGBoost pipeline](e2e-xgboost/README.html)
* [Time-series forecasting](e2e-timeseries/README.html)
  + [Setup](e2e-timeseries/README.html#setup)
  + [Acknowledgements](e2e-timeseries/README.html#acknowledgements)
* [Scalable video processing](object-detection/README.html)
* [Distributed RAG pipeline](e2e-rag/README.html)
  + [Notebooks](e2e-rag/README.html#notebooks)
* [Deploy MCP servers](mcp-ray-serve/README.html)
  + [Why Ray Serve for MCP](mcp-ray-serve/README.html#why-ray-serve-for-mcp)
  + [Anyscale service benefits](mcp-ray-serve/README.html#anyscale-service-benefits)
  + [Prerequisites](mcp-ray-serve/README.html#prerequisites)
  + [Development](mcp-ray-serve/README.html#development)
  + [Production](mcp-ray-serve/README.html#production)
  + [No infrastructure headaches](mcp-ray-serve/README.html#no-infrastructure-headaches)
* [Build a tool-using agent](langchain_agent_ray_serve/content/README.html)
  + [Architecture overview](langchain_agent_ray_serve/content/README.html#architecture-overview)
  + [Dependencies and compute resource requirements](langchain_agent_ray_serve/content/README.html#dependencies-and-compute-resource-requirements)
  + [Implementation: Building the services](langchain_agent_ray_serve/content/README.html#implementation-building-the-services)
  + [Deploy the services](langchain_agent_ray_serve/content/README.html#deploy-the-services)
  + [Test the agent](langchain_agent_ray_serve/content/README.html#test-the-agent)
  + [Next steps](langchain_agent_ray_serve/content/README.html#next-steps)

[Edit
on GitHub](https://github.com/ray-project/ray/edit/master/doc/source/ray-overview/examples/index.rst)